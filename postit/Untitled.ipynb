{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "\n",
    "\"\"\"\n",
    "Usage: import the module (see Jupyter notebooks for examples), or run from\n",
    "       the command line as such:\n",
    "    # Train a new model starting from pre-trained COCO weights\n",
    "    python3 balloon.py train --dataset=/path/to/balloon/dataset --weights=coco\n",
    "    # Resume training a model that you had trained earlier\n",
    "    python3 balloon.py train --dataset=/path/to/balloon/dataset --weights=last\n",
    "    # Train a new model starting from ImageNet weights\n",
    "    python3 balloon.py train --dataset=/path/to/balloon/dataset --weights=imagenet\n",
    "    # Apply color splash to an image\n",
    "    python3 balloon.py splash --weights=/path/to/weights/file.h5 --image=<URL or path to file>\n",
    "    # Apply color splash to video using the last weights you trained\n",
    "    python3 balloon.py splash --weights=last --video=<URL or path to file>\n",
    "\"\"\"\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-33c9a1025d24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPostDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#def load_postit(self, dataset_dir, subset):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-33c9a1025d24>\u001b[0m in \u001b[0;36mPostDataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#add class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"postit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"postit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m#subset has to be train or val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "class PostConfig(Config):\n",
    "\n",
    "    \"\"\"Configuration for the training\n",
    "    Derived from the base Config class\"\"\"\n",
    "\n",
    "    NAME = \"postit\"\n",
    "\n",
    "    IMAGES_PER_GPU = 2\n",
    "\n",
    "    NUM_CLASSES = 1 + 1 # Background + postit\n",
    "\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "class PostDataset(utils.Dataset):\n",
    "    \n",
    "    #def load_postit(self, dataset_dir, subset):\n",
    "\n",
    "    #add class\n",
    "    #self.add_class(\"postit\", 1, \"postit\")\n",
    "    \"\"\"\n",
    "    #subset has to be train or val\n",
    "\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "    \"\"\"\n",
    "    dataset_dir = os.path.abspath(\"../../Coco\")\n",
    "    dataset_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "    #load json file\n",
    "    #print(dataset_dir)\n",
    "    data_json = json.load(open(os.path.join(dataset_dir, \"output.json\")))\n",
    "    #print(data_json)\n",
    "\n",
    "    #iterates over all images in the json file\n",
    "\n",
    "    for i in data_json:\n",
    "        #print(i['Labeled Data'])\n",
    "\n",
    "        polygons = [g['geometry'] for g in i['Label']['Post It']]\n",
    "\n",
    "        image_path = i['Labeled Data']\n",
    "        image = skimage.io.imread(image_path)\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "\n",
    "        image_id=i['ID']\n",
    "        \"\"\"\n",
    "        self.add_image(\n",
    "        \"postit\",\n",
    "        image_id=i['ID'],\n",
    "        path=image_path,\n",
    "        width=width, height=height,\n",
    "        polygons=polygons\n",
    "        )\n",
    "        \n",
    "        \"\"\"\n",
    "        #print(len(polygons))\n",
    "        mask = np.zeros([height, width, len(polygons)],\n",
    "                        dtype=np.uint8)\n",
    "        \n",
    "        #print(mask)\n",
    "        \n",
    "        for i, p in enumerate(polygons):\n",
    "            x_values = []\n",
    "            y_values = []\n",
    "            print(p)\n",
    "            for x in p:\n",
    "                x_values.append(x['x'])\n",
    "                y_values.append(x['y'])\n",
    "\n",
    "            #print(x_values)\n",
    "            #print(y_values)\n",
    "            rr, cc = skimage.draw.polygon(y_values, x_values)\n",
    "            print(i)\n",
    "\n",
    "            mask[rr, cc, i] = 1\n",
    "            #print(mask)\n",
    "\n",
    "        visualize.display_top_masks(image, mask, 1, \"postit\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
